# -*- coding: utf-8 -*-
"""dpn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ezL5eO_vKjkYajej-vgmYUjKhIRG64Ar
"""

import tensorflow as tf
from keras.datasets import cifar10
import numpy as np

G = 32
EPOCH = 5
BATCH_SIZE = 16

def conv2d(layer, w_name, w_shape, b_name, b_shape, strides=[1, 1, 1, 1]):
 
  # with tf.Graph().as_default() as graph:
  w = tf.get_variable(name=w_name, shape=w_shape, dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())
  b = tf.get_variable(name=b_name, shape=b_shape, dtype=tf.float32, initializer=tf.zeros_initializer())
  layer = tf.nn.conv2d(input=layer, filter=w, strides=strides, padding='SAME')
  layer = tf.add(b, layer)

  return layer

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

tf.reset_default_graph()

x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name='x')
y = tf.placeholder(tf.int32, shape=[None, 1], name='y')

#conv_1
layer = conv2d(layer=x, w_name='w0', w_shape=[7, 7, 3, 64], b_name='b0', b_shape=[64], strides=[1, 2, 2, 1])

#conv_2 

layer = tf.nn.max_pool(value=layer, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')
layer = conv2d(layer=layer, w_name="w1-conv2--1", w_shape=[1, 1, 64, 96], b_name='b1-conv2--1', b_shape=[96], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w2-conv2--1", w_shape=[3, 3, 96, 96], b_name='b2-conv2--1', b_shape=[96], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w3-conv2--1", w_shape=[1, 1, 96, 256], b_name='b3-conv2--1', b_shape=[256], strides=[1, 1, 1, 1])
list_of_g = layer

for g in range (G-1):
  layer = conv2d(layer=layer, w_name="w1-conv2-"+str(g), w_shape=[1, 1, 256, 96], b_name='b1-conv2-'+str(g), b_shape=[96], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w2-conv2-"+str(g), w_shape=[3, 3, 96, 96], b_name='b2-conv2-'+str(g), b_shape=[96], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w3-conv2-"+str(g), w_shape=[1, 1, 96, 256], b_name='b3-conv2-'+str(g), b_shape=[256], strides=[1, 1, 1, 1])
  list_of_g = tf.concat([list_of_g, layer], axis=3)

layer = conv2d(layer=list_of_g, w_name='final_w_conv2', w_shape=[1, 1, list_of_g.get_shape().as_list()[3], 96], b_shape=[96], b_name='final_b_conv2', strides=[1, 1, 1, 1])

dense_path = layer
resnet_path = layer

#conv_3

layer = conv2d(layer=layer, w_name="w1-conv3--1", w_shape=[1, 1, 96, 192], b_name='b1-conv3--1', b_shape=[192], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w2-conv3--1", w_shape=[3, 3, 192, 192], b_name='b2-conv3--1', b_shape=[192], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w3-conv3--1", w_shape=[1, 1, 192, 512], b_name='b3-conv3--1', b_shape=[512], strides=[1, 1, 1, 1])
list_of_g = layer

for g in range (G-1):
  layer = conv2d(layer=layer, w_name="w1-conv3-"+str(g), w_shape=[1, 1, 512, 192], b_name='b1-conv3-'+str(g), b_shape=[192], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w2-conv3-"+str(g), w_shape=[3, 3, 192, 192], b_name='b2-conv3-'+str(g), b_shape=[192], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w3-conv3-"+str(g), w_shape=[1, 1, 192, 512], b_name='b3-conv3-'+str(g), b_shape=[512], strides=[1, 1, 1, 1])
  list_of_g = tf.concat([list_of_g, layer], axis=3)

layer = conv2d(layer=list_of_g, w_name='final_w_conv3', w_shape=[1, 1, list_of_g.get_shape().as_list()[3], 192], b_shape=[192], b_name='final_b_conv3', strides=[1, 1, 1, 1])

dense_path = tf.concat([dense_path, layer], axis=3)
resnet_path = tf.add(resnet_path, layer[:,:,:,:96])
layer = tf.concat([dense_path, resnet_path], axis=3)

#conv_4

layer = conv2d(layer=layer, w_name="w1-conv4--1", w_shape=[1, 1, 384, 384], b_name='b1-conv4--1', b_shape=[384], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w2-conv4--1", w_shape=[3, 3, 384, 384], b_name='b2-conv4--1', b_shape=[384], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w3-conv4--1", w_shape=[1, 1, 384, 1024], b_name='b3-conv4--1', b_shape=[1024], strides=[1, 1, 1, 1])
list_of_g = layer

for g in range (G-1):
  layer = conv2d(layer=layer, w_name="w1-conv4-"+str(g), w_shape=[1, 1, 1024, 384], b_name='b1-conv4-'+str(g), b_shape=[384], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w2-conv4-"+str(g), w_shape=[3, 3, 384, 384], b_name='b2-conv4-'+str(g), b_shape=[384], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w3-conv4-"+str(g), w_shape=[1, 1, 384, 1024], b_name='b3-conv4-'+str(g), b_shape=[1024], strides=[1, 1, 1, 1])
  list_of_g = tf.concat([list_of_g, layer], axis=3)

layer = conv2d(layer=list_of_g, w_name='final_w_conv4', w_shape=[1, 1, list_of_g.get_shape().as_list()[3], 384], b_shape=[384], b_name='final_b_conv4', strides=[1, 1, 1, 1])

dense_path = tf.concat([dense_path, layer], axis=3)
resnet_path = tf.add(resnet_path, layer[:,:,:,:96])
layer = tf.concat([dense_path, resnet_path], axis=3)
  
#conv_5

layer = conv2d(layer=layer, w_name="w1-conv5--1", w_shape=[1, 1, 768, 768], b_name='b1-conv5--1', b_shape=[768], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w2-conv5--1", w_shape=[3, 3, 768, 768], b_name='b2-conv5--1', b_shape=[768], strides=[1, 1, 1, 1])
layer = conv2d(layer=layer, w_name="w3-conv5--1", w_shape=[1, 1, 768, 2048], b_name='b3-conv5--1', b_shape=[2048], strides=[1, 1, 1, 1])
list_of_g = layer

for g in range (G-1):
  layer = conv2d(layer=layer, w_name="w1-conv5-"+str(g), w_shape=[1, 1, 2048, 768], b_name='b1-conv5-'+str(g), b_shape=[768], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w2-conv5-"+str(g), w_shape=[3, 3, 768, 768], b_name='b2-conv5-'+str(g), b_shape=[768], strides=[1, 1, 1, 1])
  layer = conv2d(layer=layer, w_name="w3-conv5-"+str(g), w_shape=[1, 1, 768, 2048], b_name='b3-conv5-'+str(g), b_shape=[2048], strides=[1, 1, 1, 1])
  list_of_g = tf.concat([list_of_g, layer], axis=3)

layer = conv2d(layer=list_of_g, w_name='final_w_conv5', w_shape=[1, 1, list_of_g.get_shape().as_list()[3], 768], b_shape=[768], b_name='final_b_conv5', strides=[1, 1, 1, 1])

dense_path = tf.concat([dense_path, layer], axis=3)
resnet_path = tf.add(resnet_path, layer[:,:,:,:96])
layer = tf.concat([dense_path, resnet_path], axis=3)  
  
layer = tf.contrib.layers.flatten(inputs=layer)
w_flat = tf.get_variable(name='w_flat', shape=[layer.shape[1], 10], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())
b_flat = tf.get_variable(name='b_flat', shape=[10], dtype=tf.float32, initializer=tf.zeros_initializer())
layer = tf.matmul(layer, w_flat)
final = tf.add( name='cifar_output', x=b_flat, y=layer)

# loss
global_step = tf.train.get_or_create_global_step()
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(tf.cast(y, dtype=tf.int32), 10), logits=final))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(loss, global_step=global_step)

# prediction
softmax = tf.argmax(tf.nn.softmax(logits=final), axis=1, output_type=tf.int32)
softmax = tf.reshape(softmax, [16, 1])
prediction = tf.reduce_mean(tf.cast(tf.equal(softmax, y), dtype=tf.float32))


#saver = tf.train.Saver()

with tf.Session() as sess:
  
  sess.run(tf.global_variables_initializer())
  #saver.restore(sess, tf.train.latest_checkpoint('./cifar-10'))
  
  for epoch in range(EPOCH):
    total_steps = int(x_train.shape[0]/BATCH_SIZE)
    for step in range(total_steps):
      x_batch = x_train[step*BATCH_SIZE:step*BATCH_SIZE + BATCH_SIZE].reshape(BATCH_SIZE, 32, 32, 3)
      y_batch = y_train[step*BATCH_SIZE:step*BATCH_SIZE + BATCH_SIZE].reshape(BATCH_SIZE, 1)
      
      current_global_step, _, current_loss= sess.run([global_step, optimizer, loss], feed_dict={x:x_batch, y:y_batch})
      print("epoch: %d global_step: %d, step: %d loss: %f" % (epoch+1, current_global_step, step, current_loss))

      if step % 10 == 0:
        xtest_batch = x_test[:BATCH_SIZE].reshape(BATCH_SIZE, 32, 32, 3)
        ytest_batch = y_test[:BATCH_SIZE].reshape(BATCH_SIZE, 1)
        softmax_p, accuracy = sess.run([softmax, prediction], feed_dict={x: xtest_batch, y: ytest_batch})
        saver.save(sess, save_path='~/saved_models/unet/cifar-10/model.chkpt', global_step=current_global_step)

        print("accuracy: %f%%" % (accuracy*100))
    
    tf.train.write_graph(sess.graph, '~/saved_models/unet/cifar-10/', 'final_graph.pb', as_text=False)
    tf.train.export_meta_graph('~/saved_models/unet/cifar-10/final_graph.meta', graph=graph, clear_devices=True)




